{"cells":[{"cell_type":"markdown","metadata":{"id":"c8Jt0CNtKy9F"},"source":["# DL Assignment 4 - Conditional Generative Adversarial Networks\n","\n","Welcome to the **fourth graded assignment** of the DL course. In the last lab, you implemented a generative adversarial network (GAN) for generating some flower imagery. However, you had no control on the type of flower to be generated. \n","In this assignment, you will implement a **conditional generative adversarial network** (cGAN) to incorporate class information into the training and generation process in order to control what the model will generate.\n","\n","***\n","\n","**Instructions**\n","- You'll be using Python 3 in the iPython based Google Colaboratory\n","- Lines encapsulated in \"<font color='green'>`### START YOUR CODE HERE ###`</font>\" and \"<font color='green'>`### END YOUR CODE HERE ###`</font>\", or marked by \"<font color='green'>`# TODO`</font>\", denote the code fragments to be completed by you.\n","- There's no need to write any other code.\n","- After writing your code, you can run the cell by either pressing `SHIFT`+`ENTER` or by clicking on the play symbol on the left side of the cell.\n","- We may specify \"<font color='green'>`(≈ X LOC)`</font>\" to tell you about how many lines of code you need to write. This is just a rough estimate, so don't feel bad if your code is longer or shorter.\n","\n","**Much success!**\n","\n","***\n","\n","<font color='darkblue'>\n","  \n","**Remember**  \n","- Run your cells using `SHIFT`+`ENTER` (or \"Run cell\")\n","- Write code in the designated areas using Python 3 only\n","- Do not modify the code outside of the designated areas\n","- Do not import/use any other packages. Code relying on packages other than the provided ones won't be graded.\n","- Activate GPU acceleration by clicking `Runtime` -> `Change runtime type` and select `GPU` from the dropdown menu entitled `Hardware accelerator`\n","</font>\n","\n","***\n","\n","<font color='red'>\n","  \n","**Note**  \n","You have to develop and submit your own solution. If we have reasons to believe you shared or did not submit your own work, we have to consider an attempted fraud. In this case your submission will be graded zero points and we reserve additional measures.\n","</font>"]},{"cell_type":"markdown","metadata":{"id":"BuWFzPriK8bG"},"source":["# 0 - Preparation"]},{"cell_type":"markdown","metadata":{"id":"NpcQPpiNK-26"},"source":["## Imports and Test for GPU\n","\n","Execute the cells below to import the required and modules and test for GPU availability:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGyhgfcJK6yA"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","\n","!wget -nv -t 0 --show-progress https://cloud.tu-ilmenau.de/s/K5gomnsHSKGcFFR/download/utils.py\n","\n","import utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tV61K4rNLBaE","cellView":"form"},"outputs":[],"source":["#@title Print TF version and GPU stats\n","print('TensorFlow version:', tf.__version__)\n","\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","   raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name), '', sep='\\n')\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"ttjo8EdvLnKE"},"source":["# 1 - Data Preparation"]},{"cell_type":"markdown","metadata":{"id":"c63_nqPwLqPY"},"source":["At first you need to load and prepare the dataset. In this assignment, you will be using the [**MNIST** database of handwritten digits](https://www.tensorflow.org/datasets/catalog/mnist). We will use the [TensorFlow Datasets](https://www.tensorflow.org/datasets/overview) (`tfds`) to load the data. \n","\n","For image generation, it's best practice to **normalize the images to `[-1, +1]`**. In addition, you need to convert the labels from sparse encoding to **one-hot encoding**.\n","\n","**TASK**: Complete the `load_mnist` function below by implementing the functions\n","- `normalize_img`: *normalize* to `[-1, +1]`, and\n","- `encode_one_hot`: convert the labels to *one-hot encoding*\n","- Map the data splits to your functions.\n","\n","\n","*Hint*: After normalization and one-hot encoding, the data shall look look like this:\n","```\n","  Min-max and label of preprocessed sample:\n","  Example input [min/max]: [-1.0, 1.0]\n","  Example output: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DNRj2DmhGLvb"},"outputs":[],"source":["# GRADED FUNCTION: normalize_img (1 point)\n","# GRADED FUNCTION: encode_one_hot (1 point)\n","# GRADED FUNCTION: load_mnist (1 point)\n","\n","import tensorflow_datasets as tfds\n","\n","# Constant and hyperparameters\n","NUM_CLASSES =   10  # number of classes\n","BATCH_SIZE =    64  # batch size\n","IMG_SIZE =      28  # image size\n","NUM_CHANNELS =  1   # image channels\n","LATENT_SIZE =   128 # seed size\n","\n","def load_mnist():\n","\n","  def normalize_img(image, label):\n","    ### START YOUR CODE HERE ### ( ≈ 1 LOC)\n","    \n","    ### END YOUR CODE HERE ###\n","    return image, label\n","\n","  def encode_one_hot(image, label):\n","    ### START YOUR CODE HERE ### ( ≈ 1 LOC)\n","    \n","    ### END YOUR CODE HERE ###\n","    return image, label\n","\n","  def print_sample(dataset):\n","    x_sample, y_sample = list(dataset.take(1).as_numpy_iterator())[0]\n","    print(f'Example input [min/max]: [{np.min(x_sample)}, {np.max(x_sample)}]')\n","    print(f'Example output:', y_sample)\n","\n","  def prepare_dataset(dataset):\n","    dataset = dataset.cache()\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","    return dataset\n","\n","  (train_data, test_data), mnist_info = tfds.load(\n","      'mnist',\n","      split=['train', 'test'],\n","      as_supervised=True,\n","      shuffle_files=True,\n","      with_info=True\n","  )\n","\n","  fig = tfds.show_examples(train_data, mnist_info)\n","\n","  print('\\nMin-max and label of original sample:')\n","  print_sample(train_data)\n","\n","  # map splits to preprocessing functions\n","  ### START YOUR CODE HERE ### ( ≈ 2 LOC)  \n","  \n","  ### END YOUR CODE HERE ###\n","\n","  print('\\nMin-max and label of preprocessed sample:')\n","  print_sample(train_data)\n","\n","  # create batches\n","  train_data = prepare_dataset(train_data)\n","  test_data = prepare_dataset(test_data)\n","\n","  return train_data, test_data\n","\n","train_data, test_data = load_mnist()"]},{"cell_type":"markdown","source":["# 2 - Build Generator and Discriminator"],"metadata":{"id":"-Wv_Wm5pAYhx"}},{"cell_type":"markdown","source":["You will implement the conditioning mechanism described in [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) by Mehdi Mirza and Simon Osindero. In detail, you will append the one-hot encoded class labels to the inputs for both the discriminator and the generator:\n","\n","<div>\n","<img src=\"https://machinelearningmastery.com/wp-content/uploads/2019/05/Example-of-a-Conditional-Generator-and-a-Conditional-Discriminator-in-a-Conditional-Generative-Adversarial-Network.png\" width=\"640\"/>\n","</div>\n","\n","Hence, the `generator_in_channels` and `discriminator_in_channels` amount to"],"metadata":{"id":"FWgtF1VX9Wy1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uh5rvZKFMrtq"},"outputs":[],"source":["generator_in_channels = LATENT_SIZE + NUM_CLASSES\n","print(f'Generator input channels: {generator_in_channels}')\n","\n","discriminator_in_channels = NUM_CHANNELS + NUM_CLASSES\n","print(f'Discriminator input channels: {discriminator_in_channels}')"]},{"cell_type":"markdown","source":["## 2.1 - Discriminator"],"metadata":{"id":"S1t4TeC2DnWS"}},{"cell_type":"markdown","source":["Next you need to build the models. Start with the discriminator, which is a simple convolutional neural network.\n","\n","**Task**: Complete the function `build_discriminator` to create the discriminator model as follows:\n","\n","```\n","Model: \"discriminator\"\n","________________________________________________________________________________________________________________________________\n"," Layer (type)                                            Output Shape                                       Param #             \n","================================================================================================================================\n"," input_1 (InputLayer)                                    [(None, 28, 28, 11)]                               0                   \n","                                                                                                                                \n"," conv2d (Conv2D)                                         (None, 14, 14, 64)                                 6400                \n","                                                                                                                                \n"," leaky_re_lu (LeakyReLU)                                 (None, 14, 14, 64)                                 0                   \n","                                                                                                                                \n"," batch_normalization (BatchNormalization)                (None, 14, 14, 64)                                 256                 \n","                                                                                                                                \n"," conv2d_1 (Conv2D)                                       (None, 7, 7, 128)                                  73856               \n","                                                                                                                                \n"," leaky_re_lu_1 (LeakyReLU)                               (None, 7, 7, 128)                                  0                   \n","                                                                                                                                \n"," batch_normalization_1 (BatchNormalization)              (None, 7, 7, 128)                                  512                 \n","                                                                                                                                \n"," global_max_pooling2d (GlobalMaxPooling2D)               (None, 128)                                        0                   \n","                                                                                                                                \n"," dropout (Dropout)                                       (None, 128)                                        0                   \n","                                                                                                                                \n"," dense (Dense)                                           (None, 1)                                          129                 \n","                                                                                                                                \n","================================================================================================================================\n","Total params: 81,153\n","Trainable params: 80,769\n","Non-trainable params: 384\n","________________________________________________________________________________________________________________________________\n","```\n","\n","The **dropout rate** shall be `0.2`. Think about the correct **activation function** for the discriminators output."],"metadata":{"id":"IocQDa6kAjU-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RCBBMQEkOB-1"},"outputs":[],"source":["# GRADED FUNCTION: build_discriminator (3 points)\n","\n","def build_discriminator(img_size, input_channels, summary=True):\n","\n","  ### START YOUR CODE HERE ### ( ≈ 11 LOC)\n","  \n","  ### END YOUR CODE HERE ###\n","  \n","  if summary:\n","    print(discriminator.summary(line_length=128))\n","\n","  return discriminator"]},{"cell_type":"markdown","source":["Initialize an instance of your discriminator to test the build:"],"metadata":{"id":"ngdBBkmMmbl5"}},{"cell_type":"code","source":["build_discriminator(IMG_SIZE, discriminator_in_channels, summary=True)"],"metadata":{"id":"nFKtDg8WCjSo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 - Generator\n","\n","Two different versions of a generator shall be implemented\n","- one with **transposed convolutions**, \n","- and the other one using a combination of **2D upsampling** and **convolutions**."],"metadata":{"id":"3Ng7DVR-JAO7"}},{"cell_type":"markdown","source":["### 2.2.1 - Transposed Convolutions based Generator\n","\n","The first version is using [transposed 2D convolutions](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose). \n","\n","**Task**: Complete the function `build_generator_transposed_conv` to create the following model:\n","\n","```\n","Model: \"transposed_conv_generator\"\n","________________________________________________________________________________________________________________________________\n"," Layer (type)                                            Output Shape                                       Param #             \n","================================================================================================================================\n"," input_2 (InputLayer)                                    [(None, 138)]                                      0                   \n","                                                                                                                                \n"," dense_1 (Dense)                                         (None, 6762)                                       939918              \n","                                                                                                                                \n"," leaky_re_lu_2 (LeakyReLU)                               (None, 6762)                                       0                   \n","                                                                                                                                \n"," batch_normalization_2 (BatchNormalization)              (None, 6762)                                       27048               \n","                                                                                                                                \n"," reshape (Reshape)                                       (None, 7, 7, 138)                                  0                   \n","                                                                                                                                \n"," conv2d_transpose (Conv2DTranspose)                      (None, 14, 14, 128)                                282752              \n","                                                                                                                                \n"," leaky_re_lu_3 (LeakyReLU)                               (None, 14, 14, 128)                                0                   \n","                                                                                                                                \n"," batch_normalization_3 (BatchNormalization)              (None, 14, 14, 128)                                512                 \n","                                                                                                                                \n"," conv2d_transpose_1 (Conv2DTranspose)                    (None, 28, 28, 64)                                 131136              \n","                                                                                                                                \n"," leaky_re_lu_4 (LeakyReLU)                               (None, 28, 28, 64)                                 0                   \n","                                                                                                                                \n"," batch_normalization_4 (BatchNormalization)              (None, 28, 28, 64)                                 256                 \n","                                                                                                                                \n"," conv2d_2 (Conv2D)                                       (None, 28, 28, 1)                                  1601                \n","                                                                                                                                \n","================================================================================================================================\n","Total params: 1,383,223\n","Trainable params: 1,369,315\n","Non-trainable params: 13,908\n","```\n","Think about the **correct activation function** for the output layer."],"metadata":{"id":"pySGyntVFRuO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6FIgzj1qO7Ry"},"outputs":[],"source":["# GRADED FUNCTION: build_generator_transposed_conv (5 points)\n","def build_generator_transposed_conv(input_channels, summary=True):\n","\n","  ### START YOUR CODE HERE ### ( ≈ 13 LOC)\n","  \n","  ### END YOUR CODE HERE ###\n","\n","  if summary:\n","    print(generator.summary(line_length=128))\n","\n","  return generator"]},{"cell_type":"markdown","source":["Initialize an instance of your generator to test the build:"],"metadata":{"id":"YA4ZFPIPmaIH"}},{"cell_type":"code","source":["build_generator_transposed_conv(generator_in_channels)"],"metadata":{"id":"RyRZ6y3wHPZO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xrr8JRBBtkOV"},"source":["### 2.2.2 - Resize Convolutions based Generator\n","\n","The second version is using the [resize-convolution approach](https://distill.pub/2016/deconv-checkerboard/) discussed in Lab 4.1. This approach is based on [`Upsampling2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D) layers followed by conventional [`Convolution2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) layers. Ultimately, the model shall look as defined as follows:\n","```\n","Model: \"resize_conv_generator\"\n","________________________________________________________________________________________________________________________________\n"," Layer (type)                                            Output Shape                                       Param #             \n","================================================================================================================================\n"," input_3 (InputLayer)                                    [(None, 138)]                                      0                   \n","                                                                                                                                \n"," dense_2 (Dense)                                         (None, 6762)                                       939918              \n","                                                                                                                                \n"," leaky_re_lu_5 (LeakyReLU)                               (None, 6762)                                       0                   \n","                                                                                                                                \n"," batch_normalization_5 (BatchNormalization)              (None, 6762)                                       27048               \n","                                                                                                                                \n"," reshape_1 (Reshape)                                     (None, 7, 7, 138)                                  0                   \n","                                                                                                                                \n"," up_sampling2d (UpSampling2D)                            (None, 14, 14, 138)                                0                   \n","                                                                                                                                \n"," conv2d_3 (Conv2D)                                       (None, 14, 14, 128)                                159104              \n","                                                                                                                                \n"," leaky_re_lu_6 (LeakyReLU)                               (None, 14, 14, 128)                                0                   \n","                                                                                                                                \n"," batch_normalization_6 (BatchNormalization)              (None, 14, 14, 128)                                512                 \n","                                                                                                                                \n"," up_sampling2d_1 (UpSampling2D)                          (None, 28, 28, 128)                                0                   \n","                                                                                                                                \n"," conv2d_4 (Conv2D)                                       (None, 28, 28, 64)                                 73792               \n","                                                                                                                                \n"," leaky_re_lu_7 (LeakyReLU)                               (None, 28, 28, 64)                                 0                   \n","                                                                                                                                \n"," batch_normalization_7 (BatchNormalization)              (None, 28, 28, 64)                                 256                 \n","                                                                                                                                \n"," conv2d_5 (Conv2D)                                       (None, 28, 28, 1)                                  577                 \n","                                                                                                                                \n","================================================================================================================================\n","Total params: 1,201,207\n","Trainable params: 1,187,299\n","Non-trainable params: 13,908\n","```\n","\n","**Task**: Complete the function `build_generator_resize_conv`:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLIGdj3dhlZY"},"outputs":[],"source":["# GRADED FUNCTION: build_generator_resize_conv and plot history (5 points)\n","def build_generator_resize_conv(input_channels, summary=True):\n","\n","  ### START YOUR CODE HERE ### ( ≈ 15 LOC)\n","  \n","  ### END YOUR CODE HERE ###\n","\n","  if summary:\n","    print(generator.summary(line_length=128))\n","\n","  return generator"]},{"cell_type":"markdown","source":["Initialize an instance of your resize-conv generator to test the build:"],"metadata":{"id":"NQWueObqmR4R"}},{"cell_type":"code","source":["build_generator_resize_conv(generator_in_channels)"],"metadata":{"id":"TDUPaSBYMvE2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 - Train!\n","\n","Now it's time to train the two versions of your conditional GAN."],"metadata":{"id":"US5OsS_LWJRn"}},{"cell_type":"markdown","metadata":{"id":"ZOJb649vt1zl"},"source":["## 3.1 - Transposed Convolution based Generator\n","\n","Execute the next cell to run the training:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lRvmBR8ARFAK"},"outputs":[],"source":["cgan_transposed_conv, cgan_transposed_conv_history = utils.train_gan(\n","    build_discriminator(IMG_SIZE, discriminator_in_channels, summary=False),\n","    build_generator_transposed_conv(generator_in_channels, summary=False),\n","    train_data,\n","    epochs=20\n",")\n","\n","utils.plot_history(cgan_transposed_conv_history)"]},{"cell_type":"markdown","metadata":{"id":"kJfIxEjwt5kQ"},"source":["## 3.2 - Resize Convolution based Generator\n","\n","**Task**: Train a GAN using the resize convolutions-based generator and plot the history. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJHzM1oVi7zJ"},"outputs":[],"source":["# GRADED: train resize-convolution GAN (1 point)\n","\n","### START YOUR CODE HERE ### ( ≈ 2 LOC)\n","\n","cgan_resize_conv, cgan_resize_conv_history = \n","\n","### END YOUR CODE HERE ###"]},{"cell_type":"markdown","source":["# 4 - Interpolate Classes\n","\n","Instead of using one-hot encoded vectors as class labels, you can also use the generator to create images for **interpolated classes**. \n","\n","The idea is as follows: the generator shall create a defined number of images. The number of images is defined as `steps`. The first image shall show the class with `class_one_idx` and the last image shall show `class_two_idx`. The images in between shall display interpolations between these two classes. Per step, the class labels transition from `class_one_idx` to `class_two_idx`. \n","Example: the first interpolated image shall represent 75% of `class_one_idx` and 25% of `class_two_idx`. The next interpolated image shall represent 50% of `class_one_idx` and 50% of `class_two_idx`, and so on.\n","\n","Therefore, the task is twofold:\n","\n","1) The generator requires a random seed. To observe only the impact of the class interpolation **the same seed shall be reused for all generation steps**. Hence, you need to generate a random seed vector and then repeat it for the number of images to be generated (=`steps`).\n","\n","Example: consider 3 steps and a seed length (=`LATENT_SIZE`) of 4, the `gen_seed` array could be:\n","```\n","[[-0.62280726 -0.25039887  0.02668798 -1.9732285 ]\n"," [-0.62280726 -0.25039887  0.02668798 -1.9732285 ]\n"," [-0.62280726 -0.25039887  0.02668798 -1.9732285 ]]\n","```\n","\n","2) In addition to the seed, the generator is conditioned by class probability vectors concatenated to the random seed. During training, these were one-hot encoded vectors because each image displays exactly one class. To interpolate between classes, you need to generate class probability vectors that transition from `class_one_idx` to `class_two_idx` in a given number of steps. \n","\n","Example: consider 10 classes and 3 steps, `class_one_idx = 2` and `class_two_idx`= 5, the `cl_interp` array should be:\n","```\n","[[0.   0.   1.   0.   0.   0.   0.   0.   0.   0.  ]\n"," [0.   0.   0.5  0.   0.   0.5  0.   0.   0.   0.  ]\n"," [0.   0.   0.   0.   0.   1.   0.   0.   0.   0.  ]]\n","```\n","\n","In order to do so, you just need to implement the following steps:\n","- Sample a noise vector of shape `(1, LATENT_SIZE)` from a normal distribution.\n","- Repeat the noise vector along the first axis for `steps` to obtain a vector of shape `(steps, LATENT_SIZE)`.\n","- Interpolate the one-hot encoded labels, i.e., \n"," - at index `class_one_idx`: continuously decrease values from `1` to `0` for `steps` number of steps (or stepsize = `1./steps`);\n"," - at index `class_two_idx`: continuously increase values from `0` to `1` for `steps` number of steps (or stepsize = `1./steps`).\n","\n","\n","**Task**: Complete the function `interpolate_classes` following the described steps."],"metadata":{"id":"3JHvFCfKbdma"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"oPLxBer6i9xU"},"outputs":[],"source":["# GRADED FUNCTION: interpolate_classes (3 points)\n","\n","def interpolate_classes(cgan, class_one_idx, class_two_idx, steps=32):\n","\n","  for x in (class_one_idx, class_two_idx):\n","    assert x in range(NUM_CLASSES), f'input must be in {range(NUM_CLASSES)}'\n","    assert class_one_idx != class_two_idx, \"use dissimilar classes\"\n","\n","  ### START YOUR CODE HERE ### ( ≈ 4 LOC)\n","  \n","  # Get random seed for generator\n","  gen_seed = \n","\n","  # Repeat random seed for `steps` time\n","  gen_seed = \n","\n","  # Interpolate one-hot encoded labels\n","  class_interp = np.zeros( (steps, NUM_CLASSES) )\n","  class_interp[:, class_one_idx] = \n","  class_interp[:, class_two_idx] = \n","\n","  ### END YOUR CODE HERE ###\n","\n","  gen_seed = tf.concat([gen_seed, class_interp], axis=1)\n","\n","  # Generate images based on interpolated labels\n","  generated_images = cgan.generator(gen_seed)\n","  generated_images = (generated_images + 1)/2.\n","  generated_images.numpy()\n","\n","  return generated_images"]},{"cell_type":"markdown","source":["Now you can interpolate between two classes, e.g., 0 and 9, and plot the resulting images:"],"metadata":{"id":"2J7rz6D9D3wx"}},{"cell_type":"code","source":["utils.plot_interpolated_images( interpolate_classes(cgan_transposed_conv, 0, 9) )"],"metadata":{"id":"SRTQmNkVghsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["utils.plot_interpolated_images( interpolate_classes(cgan_resize_conv, 0, 9) )"],"metadata":{"id":"hnJgJeOgtAm4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","# Congratulations on completing Assignment 4!\n","\n","Complete the steps below for submission.\n","\n","# Submission Instructions\n","\n","You may now submit your notebook to moodle:\n","- Save the notebook (`CTRL`+ `s` or '*File*' -> '*Save*')\n","- Click on '*File*' -> '*Download .ipynb*' for downloading the notebook as IPython Notebook file.\n","- Upload the downloaded IPython Notebook file to **Moodle**."],"metadata":{"id":"FRSDn3yiPs6r"}}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[],"authorship_tag":"ABX9TyOzkLQi3nbKqBwNX8UdC7Dd"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}